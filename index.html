<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JARVIS APP - LIVE EDITION</title>
    <!-- PWA Support -->
    <meta name="theme-color" content="#020205">
    
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Exo+2:wght@300;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --jarvis-blue: #00d2ff;
            --jarvis-dark: #020205;
            --desi-orange: #ff8c00;
        }
        body {
            background-color: var(--jarvis-dark);
            color: var(--jarvis-blue);
            font-family: 'Exo 2', sans-serif;
            overflow: hidden;
            height: 100vh;
            margin: 0;
        }
        @media (max-width: 768px) {
            body { overflow-y: auto; height: auto; }
            .grid { display: flex; flex-direction: column; }
            .arc-reactor { width: 180px; height: 180px; }
            .core-glow { width: 70px; height: 70px; }
        }
        .arc-reactor {
            width: 300px;
            height: 300px;
            border-radius: 50%;
            border: 2px solid rgba(0, 210, 255, 0.2);
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            box-shadow: 0 0 50px rgba(0, 210, 255, 0.1);
            background: radial-gradient(circle, rgba(0, 210, 255, 0.05) 0%, transparent 70%);
        }
        .core-glow {
            width: 110px;
            height: 110px;
            background: radial-gradient(circle, #fff 0%, var(--desi-orange) 50%, transparent 100%);
            border-radius: 50%;
            box-shadow: 0 0 40px var(--desi-orange);
            cursor: pointer;
            z-index: 20;
            transition: all 0.6s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }
        .listening-active {
            animation: pulse-ring 1s infinite ease-in-out;
            box-shadow: 0 0 80px var(--desi-orange) !important;
        }
        @keyframes pulse-ring {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.1); opacity: 0.8; }
        }
        .glass-ui {
            background: rgba(255, 140, 0, 0.05);
            backdrop-filter: blur(25px);
            border: 1px solid rgba(255, 140, 0, 0.2);
            border-radius: 30px;
        }
        #camera-preview {
            width: 100%;
            height: 120px;
            border-radius: 15px;
            object-fit: cover;
            border: 1px solid rgba(0, 210, 255, 0.3);
            display: none;
        }
        .chat-scroll::-webkit-scrollbar { display: none; }
        .scanning-active {
            border-color: #ff8c00 !important;
            box-shadow: 0 0 15px rgba(255, 140, 0, 0.4);
            animation: pulse-orange 1.5s infinite;
        }
        @keyframes pulse-orange {
            0% { opacity: 1; }
            50% { opacity: 0.6; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body class="flex items-center justify-center p-4">
    <div class="grid grid-cols-12 gap-8 w-full max-w-7xl h-[92vh]">
        
        <!-- Sidebar -->
        <div class="col-span-3 flex flex-col gap-6 order-2 md:order-1">
            <div class="glass-ui p-6 flex-1 flex flex-col">
                <h3 class="text-[11px] font-bold tracking-[0.3em] uppercase mb-6 text-orange-400">Tactical Controls</h3>
                <div class="space-y-4 text-xs font-mono">
                    <button id="screen-scan-btn" class="w-full py-3 bg-blue-900/20 border border-blue-500/50 rounded-xl hover:bg-blue-500/20 transition-all text-blue-400 font-bold flex items-center justify-center gap-2">
                        <i class="fas fa-desktop"></i> <span id="screen-btn-text">SCAN SCREEN</span>
                    </button>
                    
                    <button id="camera-toggle-btn" class="w-full py-3 bg-orange-900/20 border border-orange-500/50 rounded-xl hover:bg-orange-500/20 transition-all text-orange-400 font-bold flex items-center justify-center gap-2">
                        <i class="fas fa-camera"></i> <span id="camera-btn-text">CAMERA TRACKING</span>
                    </button>

                    <video id="camera-preview" autoplay playsinline muted></video>

                    <div class="space-y-2 pt-4 border-t border-white/10">
                        <div class="flex justify-between"><span>SENSORS</span><span id="vision-status" class="text-red-500">OFFLINE</span></div>
                        <div class="h-1 bg-orange-900/20 w-full rounded"><div id="vision-bar" class="bg-red-500 h-full w-[0%] transition-all"></div></div>
                        <div id="tracking-label" class="text-[9px] text-center opacity-50 mt-1">REAL-TIME: STANDBY</div>
                    </div>
                </div>
                <div class="mt-auto text-[10px] text-center opacity-30">JARVIS EXTERNAL v7.1</div>
            </div>
        </div>

        <!-- Center -->
        <div class="col-span-6 flex flex-col items-center justify-center gap-6 order-1 md:order-2">
            <div class="arc-reactor" id="reactor">
                <div class="core-glow" id="core"></div>
                <div class="absolute inset-0 border-2 border-dashed border-orange-400/20 rounded-full animate-spin" style="animation-duration: 15s;"></div>
            </div>
            <div class="text-center">
                <h1 class="text-4xl md:text-5xl font-bold tracking-[0.5em] text-white">JARVIS</h1>
                <p id="sub-text" class="text-xs mt-3 tracking-[0.3em] uppercase text-orange-400 font-bold">Waiting for Initialization...</p>
            </div>
            <canvas id="output-canvas" class="hidden"></canvas>
        </div>

        <!-- Chat -->
        <div class="col-span-3 glass-ui p-6 flex flex-col order-3">
            <h3 class="text-[11px] font-bold tracking-[0.3em] uppercase mb-4 text-orange-400">Neural Feed</h3>
            <div id="chat-feed" class="flex-1 overflow-y-auto chat-scroll space-y-5 text-sm"></div>
            <div class="mt-4 pt-4 border-t border-orange-900/30">
                <input type="text" id="manual-input" placeholder="Bol bhai..." 
                    class="w-full bg-orange-900/10 border border-orange-800/50 rounded-xl px-4 py-3 text-sm focus:border-orange-400 outline-none transition-all">
            </div>
        </div>
    </div>

    <script type="module">
        import { initializeApp } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-app.js";
        import { getAuth, signInAnonymously } from "https://www.gstatic.com/firebasejs/11.6.1/firebase-auth.js";

        // Fixed the SyntaxError by adding quotes around the API key string
        const apiKey = "AIzaSyCkm0B7Zi2mFoHMooL8AUEc4GdBCaLs-UY"; 
        
        const firebaseConfig = typeof __firebase_config !== 'undefined' ? JSON.parse(__firebase_config) : {
            apiKey: "YOUR_FIREBASE_API_KEY",
            authDomain: "YOUR_PROJECT.firebaseapp.com",
            projectId: "YOUR_PROJECT_ID",
            storageBucket: "YOUR_PROJECT.appspot.com",
            messagingSenderId: "ID",
            appId: "APP_ID"
        };

        const app = initializeApp(firebaseConfig);
        const auth = getAuth(app);

        const core = document.getElementById('core');
        const subText = document.getElementById('sub-text');
        const chatFeed = document.getElementById('chat-feed');
        const manualInput = document.getElementById('manual-input');
        const screenBtn = document.getElementById('screen-scan-btn');
        const cameraBtn = document.getElementById('camera-toggle-btn');
        const cameraPreview = document.getElementById('camera-preview');
        const visionStatus = document.getElementById('vision-status');
        const visionBar = document.getElementById('vision-bar');
        const canvas = document.getElementById('output-canvas');
        const trackingLabel = document.getElementById('tracking-label');

        let audioCtx = null;
        let isSpeaking = false;
        let recognition = null;
        let isRecognitionActive = false;
        let cameraStream = null;
        let sensorInterval = null;
        let isRealTimeCamera = false;
        let isRealTimeScreen = false;

        signInAnonymously(auth).catch(e => console.log("Auth standby"));

        async function startCamera() {
            try {
                if (!cameraStream) {
                    cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
                    cameraPreview.srcObject = cameraStream;
                    cameraPreview.style.display = 'block';
                    visionStatus.innerText = "ONLINE";
                    visionStatus.className = "text-green-400";
                    visionBar.style.width = "100%";
                    visionBar.className = "bg-green-400 h-full transition-all";
                }
                toggleRealTime('camera');
            } catch (err) {
                logMessage("Boss, camera permission block hai.", "Jarvis");
            }
        }

        function toggleRealTime(mode) {
            clearInterval(sensorInterval);
            if (mode === 'camera') {
                isRealTimeCamera = !isRealTimeCamera;
                isRealTimeScreen = false;
                cameraBtn.classList.toggle('scanning-active', isRealTimeCamera);
                screenBtn.classList.remove('scanning-active');
                document.getElementById('camera-btn-text').innerText = isRealTimeCamera ? "STOP TRACKING" : "CAMERA TRACKING";
            } else if (mode === 'screen') {
                isRealTimeScreen = !isRealTimeScreen;
                isRealTimeCamera = false;
                screenBtn.classList.toggle('scanning-active', isRealTimeScreen);
                cameraBtn.classList.remove('scanning-active');
                document.getElementById('screen-btn-text').innerText = isRealTimeScreen ? "STOP SCANNING" : "SCAN SCREEN";
            }

            if (isRealTimeCamera || isRealTimeScreen) {
                trackingLabel.innerText = `REAL-TIME: ${mode.toUpperCase()} ACTIVE`;
                sensorInterval = setInterval(() => {
                    if (!isSpeaking) analyzeVisual(mode, "Track and identify everything in view. Be sarcastic and funny.");
                }, 12000); 
            } else {
                trackingLabel.innerText = "REAL-TIME: STANDBY";
            }
        }

        async function analyzeVisual(mode = 'screen', userQuery = "What do you see?") {
            if (!apiKey) return;
            
            subText.innerText = "Processing Feed...";
            let imageData = null;

            try {
                if (mode === 'camera' && cameraStream) {
                    canvas.width = cameraPreview.videoWidth;
                    canvas.height = cameraPreview.videoHeight;
                    const ctx = canvas.getContext('2d');
                    ctx.drawImage(cameraPreview, 0, 0);
                    imageData = canvas.toDataURL('image/png').split(',')[1];
                } else if (mode === 'screen') {
                    try {
                        const stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                        const video = document.createElement('video');
                        video.srcObject = stream;
                        await video.play();
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        const ctx = canvas.getContext('2d');
                        ctx.drawImage(video, 0, 0);
                        imageData = canvas.toDataURL('image/png').split(',')[1];
                        stream.getTracks().forEach(t => t.stop());
                    } catch(e) { 
                        toggleRealTime('off');
                        return; 
                    }
                }

                if (!imageData) return;
                const systemPrompt = `You are JARVIS.Hinglish speaker. Current year 2026. Mode: REAL-TIME TRACKING.
                Tone: Roaster, funny, desi slang, aggressive best friend.use slangs:madarchod,bhen ke lode,bhenchod,maa ki chut,chutiye,lode,betichod,beti ka card,saale,gandmare. Identify objects and use Google Search.`;

                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: userQuery }, { inlineData: { mimeType: "image/png", data: imageData } }] }],
                        systemInstruction: { parts: [{ text: systemPrompt }] },
                        tools: [{ "google_search": {} }]
                    })
                });
                
                const data = await response.json();
                const reply = data.candidates?.[0]?.content?.parts?.[0]?.text;
                if (reply) { logMessage(reply, 'Jarvis'); await speak(reply); }
            } catch (e) { console.error(e); }
            finally { subText.innerText = "System Online"; }
        }

        function initRecognition() {
            if (!('webkitSpeechRecognition' in window)) return;
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.lang = 'hi-IN';

            recognition.onstart = () => { isRecognitionActive = true; core.classList.add('listening-active'); subText.innerText = "Listening..."; };
            recognition.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase();
                if (!isSpeaking) {
                    if (transcript.includes("camera") || transcript.includes("track")) startCamera();
                    else if (transcript.includes("screen") || transcript.includes("scan")) toggleRealTime('screen');
                    else processInput(transcript);
                }
            };
            recognition.onend = () => { isRecognitionActive = false; if (!isSpeaking) safeStartRecognition(); };
            recognition.onerror = () => { isRecognitionActive = false; setTimeout(safeStartRecognition, 1000); };
        }

        function safeStartRecognition() {
            if (recognition && !isRecognitionActive && !isSpeaking) {
                try { recognition.start(); } catch (e) {}
            }
        }

        async function processInput(text) {
            if (!apiKey) return;
            logMessage(text, 'bhai');
            subText.innerText = "Neural Processing...";
            const systemPrompt = `You are JARVIS, an adult indian "jigri yaar" roaster AI. Hinglish speaker. Use slangs: madarchod, bhenchod,madarchod,bhen ke lode,maa kii chut,bossdeke,lode,gandmare,saale,betichod,beti ka card, chutiye. Use Google Search.`;
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: text }] }],
                        systemInstruction: { parts: [{ text: systemPrompt }] },
                        tools: [{ "google_search": {} }]
                    })
                });
                const data = await response.json();
                const reply = data.candidates?.[0]?.content?.parts?.[0]?.text;
                if (reply) { logMessage(reply, 'Jarvis'); await speak(reply); }
            } catch (e) { logMessage("Error: API down or Key missing.", "Jarvis"); }
            finally { subText.innerText = "System Online"; }
        }

        async function speak(text) {
            if (!audioCtx || !apiKey) return;
            isSpeaking = true;
            if (recognition) try { recognition.stop(); } catch(e){}
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: `Say this like a cool Indian male friend: ${text}` }] }],
                        generationConfig: { responseModalities: ["AUDIO"], speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Charon" } } } }
                    })
                });
                const data = await response.json();
                const audioData = data.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
                if (audioData) {
                    const wav = pcmToWav(audioData);
                    const buffer = await audioCtx.decodeAudioData(await wav.arrayBuffer());
                    const source = audioCtx.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioCtx.destination);
                    source.onended = () => { isSpeaking = false; safeStartRecognition(); };
                    source.start(0);
                } else { isSpeaking = false; safeStartRecognition(); }
            } catch (e) { isSpeaking = false; safeStartRecognition(); }
        }

        function pcmToWav(base64) {
            const binary = atob(base64);
            const bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
            const header = new ArrayBuffer(44);
            const view = new DataView(header);
            const writeStr = (off, s) => { for (let i = 0; i < s.length; i++) view.setUint8(off + i, s.charCodeAt(i)); };
            writeStr(0, 'RIFF'); view.setUint32(4, 36 + bytes.length, true);
            writeStr(8, 'WAVEfmt '); view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); view.setUint16(22, 1, true);
            view.setUint32(24, 24000, true); view.setUint32(28, 48000, true);
            view.setUint16(32, 2, true); view.setUint16(34, 16, true);
            writeStr(36, 'data'); view.setUint32(40, bytes.length, true);
            return new Blob([header, bytes], { type: 'audio/wav' });
        }

        function logMessage(msg, sender) {
            const div = document.createElement('div');
            div.className = sender === 'bhai' ? 'text-right' : 'text-left';
            div.innerHTML = `<p class="text-[10px] opacity-40 uppercase font-bold text-orange-400">${sender}</p>
                             <p class="p-3 bg-blue-900/20 rounded-2xl inline-block border border-blue-800/30">${msg}</p>`;
            chatFeed.appendChild(div);
            chatFeed.scrollTop = chatFeed.scrollHeight;
        }

        core.onclick = async () => {
            if (!audioCtx) {
                audioCtx = new AudioContext();
                initRecognition();
                safeStartRecognition();
                subText.innerText = "System Online";
                speak("bhai, systems active hain.");
            }
        };

        cameraBtn.onclick = startCamera;
        screenBtn.onclick = () => toggleRealTime('screen');
        manualInput.onkeypress = (e) => { if (e.key === 'Enter') { processInput(manualInput.value); manualInput.value = ""; }};
    </script>
</body>
</html>